{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the sense of machine learning, what is a model? What is the best way to train a model?\n",
    "\n",
    "ANS-Machine learning models are computer programs that are used to recognize patterns in data or make predictions.\n",
    "\n",
    "Machine learning models are created from machine learning algorithms, which are trained using either labeled, unlabeled, or mixed data. Different machine learning algorithms are suited to different goals, such as classification or prediction modeling, so data scientists use different algorithms as the basis for different models. As data is introduced to a specific algorithm, it is modified to better manage a specific task and becomes a machine learning model.\n",
    "\n",
    "To train a machine learning model, you need to split the dataset into training and testing sets. You should also tune the hyperparameters and fit and tune the models. There are thousands of algorithms to choose from, and there is no sure way to determine which will be the best for any specific model1. Before you begin the training phase, you need to first determine your problem statement, access your data set and clean the data to be presented to the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the sense of machine learning, explain the \"No Free Lunch\" theorem.\n",
    "\n",
    "ANS-The no-free lunch theorem implies that we must design our machine learning algorithms to perform well on a selected task. We do so by building a group of preferences into the training algorithm. When these preferences are aligned with the training problems we ask the algorithm to unravel, it performs better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Describe the K-fold cross-validation mechanism in detail.\n",
    "\n",
    "ANS-K fold cross validation is a method of resampling the data set to evaluate a machine learning model. The data set is split into k equal sized subsets34. One subset is used as the validation data for testing the model, and the rest k-1 subsets are used as the training data. This process is repeated k times, with each subset used once as the validation data34. The score of the model on each fold is averaged to measure the performance of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Describe the bootstrap sampling method. What is the aim of it?\n",
    "\n",
    "ANS-Bootstrapping is a resampling technique that allows us to estimate uncertainty and generate a distribution of estimates. It is used to estimate statistics on a population by sampling a dataset with replacement. The procedure creates resampled datasets that are the same size as the original dataset. Bootstrapping can be used to estimate summary statistics such as the mean or standard deviation2. The basic idea of bootstrapping is that inference about a population from sample data can be modeled by resampling the sample data and performing inference about a sample from resampled data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the significance of calculating the Kappa value for a classification model? Demonstrate\n",
    "how to measure the Kappa value of a classification model using a sample collection of results.\n",
    "\n",
    "ANS-It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. Cohen’s kappa is always less than or equal to 1. Values of 0 or less, indicate that the classifier is useless.\n",
    "\n",
    "To measure the kappa value of a classification model using a sample collection of results, you can use Cohen’s kappa statistic. It is a score that expresses the level of agreement between two annotators on a classification problem. It is defined as κ = (p o − p e) / (1 − p e), where p o is the observed accuracy and p e is the expected accuracy (random chance)1.\n",
    "\n",
    "The kappa statistic can be calculated using both the Observed Accuracy and the Expected Accuracy and the formula: Kappa = (observed accuracy - expected accuracy)/ (1 - expected accuracy)2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Describe the model ensemble method. In machine learning, what part does it play?\n",
    "\n",
    "ANS-Ensemble method in Machine Learning is defined as the multimodal system in which different classifier and techniques are strategically combined into a predictive model (grouped as Sequential Model, Parallel Model, Homogeneous and Heterogeneous methods etc.) Ensemble method also helps to reduce the variance in the predicted data, minimize the biasness in the predictive model and to classify and predict the statistics from the complex problems with better accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What is a descriptive model's main purpose? Give examples of real-world problems that\n",
    "descriptive models were used to solve.\n",
    "\n",
    "ANS-A descriptive model is a way of describing data in a form that allows for future action strategies, but it is not a precise event. It describes data in clusters or association rules so it doesn’t need to be accurate, just approximate1. A descriptive model describes a system or other entity and its relationship to its environment2. A descriptive model is usually an equation chosen to fit experimental or observational data\n",
    "\n",
    "Descriptive models are used to describe what happened in the past. They are used to summarize data and provide insights into patterns and trends. Here are some examples of real-world problems that descriptive models were used to solve:\n",
    "\n",
    "Predicting customer churn rates for a telecommunications company1\n",
    "Analyzing the effectiveness of a marketing campaign1\n",
    "Identifying the factors that contribute to employee turnover1\n",
    "Analyzing the impact of climate change on crop yields2\n",
    "Predicting the likelihood of a patient being readmitted to the hospital within 30 days2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Describe how to evaluate a linear regression model.\n",
    "\n",
    "\n",
    "ANS-There are several ways to evaluate a linear regression model. Here are some common methods\n",
    "\n",
    "R-squared: This is a measure of how well the model fits the data. It ranges from 0 to 1, with higher values indicating a better fit.\n",
    "\n",
    "Mean squared error (MSE): This measures the average squared difference between the predicted and actual values. Lower values indicate a better fit.\n",
    "\n",
    "Root mean squared error (RMSE): This is the square root of the MSE. It is in the same units as the dependent variable and is easier to interpret than the MSE.\n",
    "\n",
    "Mean absolute error (MAE): This measures the average absolute difference between the predicted and actual values. Lower values indicate a better fit.\n",
    "\n",
    "Residual plots: These plots show the difference between the predicted and actual values. A good model will have residuals that are randomly distributed around zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Descriptive vs. predictive models\n",
    "\n",
    "Descriptive models are different from predictive models in that they don't need to be as accurate as predictive models1. Predictive models are used to determine what is likely to happen next, while descriptive models are used to understand what has happened2. Predictive models are used to predict future events, while descriptive models explain data using a structured form like clustering or social network analysis3. Predictive models are used in a variety of applications, including weather forecasts, creating video games, translating voice to text, customer service, and investment portfolio strategies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "Underfitting: A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on training data but performs poorly on testing data. (It’s just like trying to fit undersized pants!) Underfitting destroys the accuracy of our machine learning model.\n",
    "\n",
    "Reasons for Underfitting:\n",
    "\n",
    "High bias and low variance \n",
    "The size of the training dataset used is not enough.\n",
    "The model is too simple.\n",
    "Training data is not cleaned and also contains noise in it.\n",
    "\n",
    "Overfitting: A statistical model is said to be overfitted when the model does not make accurate predictions on testing data. When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set. And when testing with test data results in High variance. Then the model does not categorize the data correctly, because of too many details and noise. The causes of overfitting are the non-parametric and non-linear methods because these types of machine learning algorithms have more freedom in building the model based on the dataset and therefore they can really build unrealistic models\n",
    "\n",
    "Reasons for Overfitting are as follows:\n",
    " High variance and low bias \n",
    "The model is too complex\n",
    "The size of the training data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bootstrapping vs. cross-validation\n",
    "\n",
    "Cross-validation and bootstrapping are techniques used for model validation. Cross-validation splits the dataset into multiple smaller datasets, while bootstrapping resamples the original dataset with replacement1. Cross-validation is stronger than bootstrapping for model validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Make quick notes on:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-One-Out Cross Validation:\n",
    "\n",
    "Leave-one-out cross-validation uses the following approach to evaluate a model:\n",
    "\n",
    "1. Split a dataset into a training set and a testing set, using all but one observation as part of the training setNote that we only leave one observation “out” from the training set. This is where the method gets the name “leave-one-out” cross-validation.\n",
    "\n",
    "2. Build the model using only data from the training set.\n",
    "\n",
    "\n",
    "3. Use the model to predict the response value of the one observation left out of the model and calculate the MSE.\n",
    "\n",
    "4. Repeat the process n times.\n",
    "\n",
    "Lastly, we repeat this process n times (where n is the total number of observations in the dataset), leaving out a different observation from the training set each time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. F-measurement\n",
    "\n",
    "The F-measure is a metric that is used to evaluate the performance of a binary classification model. It is defined as the harmonic mean of precision and recall, and is used to balance the precision and recall of a model in a single metric. The F-measure is calculated using the following formula:\n",
    "\n",
    "F-measure = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "Where precision is the number of true positives divided by the number of true positives plus false positives, and recall is the number of true positives divided by the number of true positives plus false negatives12."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The width of a silhouette:\n",
    "\n",
    "\n",
    "The width of a silhouette can be measured in different ways depending on the context. For example, in the context of photography, silhouette image sizes for print can be 5 x 7 inches (127 x 177.8 mm; 12.7 cm x 17.78 cm) for standard photography size silhouettes1. In the context of clustering, silhouette width is a widely used index for assessing the fit of individual objects in the classification2. If you could provide more context about what you are referring to,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Receiver operating characteristic curve\n",
    "\n",
    "The receiver operating characteristic curve is a popular graphical method frequently used in order to study the diagnostic capacity of continuous markers. It represents in a plot true-positive rates against the false-positive ones.\n",
    "\n",
    "The primary method used for this process is the receiver operating characteristic (ROC) curve. The ROC curve is used to assess the overall diagnostic performance of a test and to compare the performance of two or more diagnostic tests. It is also used to select an optimal cut-off value for determining the presence or absence of a disease. Although clinicians who do not have expertise in statistics do not need to understand both the complex mathematical equation and the analytic process of ROC curves, understanding the core concepts of the ROC curve analysis is a prerequisite for the proper use and interpretation of the ROC curve\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
